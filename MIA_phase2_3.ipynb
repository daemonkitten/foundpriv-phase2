{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "54fd2d0f",
      "metadata": {
        "id": "54fd2d0f"
      },
      "source": [
        "## MIA FOR Finetuned LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a92386",
      "metadata": {
        "id": "89a92386"
      },
      "outputs": [],
      "source": [
        "# update the downloading command as my LFS runs out so cannot directly clone model.safetensors\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/daemonkitten/foundpriv-phase2.git\n",
        "\n",
        "%cd /content/18734-17731_Project_Phase2_3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c559787",
      "metadata": {
        "id": "0c559787"
      },
      "source": [
        "### Variables and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a53cf5",
      "metadata": {
        "id": "d1a53cf5"
      },
      "outputs": [],
      "source": [
        "# install the required libraries if you have not done so (on you local machine or GPU server)\n",
        "# you may not need to run this if you use colab as they are pre-installed, but you can always do it.\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54dab5ec",
      "metadata": {
        "id": "54dab5ec"
      },
      "outputs": [],
      "source": [
        "import os, math, argparse\n",
        "os.environ.setdefault(\"TRANSFORMERS_NO_TORCHVISION\", \"1\")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_from_disk\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc as _auc\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709e4b5d",
      "metadata": {
        "id": "709e4b5d"
      },
      "outputs": [],
      "source": [
        "# global variable, check the current position to adjust the path\n",
        "phase = \"train\" # or train / val / final\n",
        "target_model_dir = f\"./models/{phase}/gpt2_3_lora32_adamw_b8_lr2\"\n",
        "data_dir = f\"./data/{phase}/\"\n",
        "batch_size = 50\n",
        "\n",
        "# you may change block size if you like (max length for the tokenizer below)\n",
        "block_size = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef38029",
      "metadata": {
        "id": "fef38029"
      },
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f06ed9d",
      "metadata": {
        "id": "7f06ed9d"
      },
      "outputs": [],
      "source": [
        "def tokenize_dataset(ds, tok, max_len):\n",
        "    ds = ds.filter(lambda ex: ex.get(\"text\", None) and len(ex[\"text\"].strip()) > 0)\n",
        "\n",
        "    def _map(ex):\n",
        "        out = tok(ex[\"text\"], truncation=True, padding=True, max_length=max_len, return_attention_mask=True)\n",
        "        out[\"labels\"] = out[\"input_ids\"].copy()\n",
        "        return out\n",
        "\n",
        "    ds = ds.map(_map, batched=True, remove_columns=ds.column_names)\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "    return ds\n",
        "\n",
        "def _read_json(path: Path):\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c040ba66",
      "metadata": {
        "id": "c040ba66"
      },
      "outputs": [],
      "source": [
        "# for tests, you may only load a part of the data to save time while implementing,\n",
        "# as running all 2000 samples on CPU may be slow, but not a problem here for GPU\n",
        "\n",
        "# load test data\n",
        "data_dir = Path(data_dir)\n",
        "test_path = data_dir / \"test.json\"\n",
        "test_items = _read_json(test_path)\n",
        "ds_test = Dataset.from_dict({\"text\": test_items})\n",
        "\n",
        "# tokenizer the test data\n",
        "tokenizer = AutoTokenizer.from_pretrained(target_model_dir, use_fast=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side=\"right\"\n",
        "\n",
        "ds_test = tokenize_dataset(ds_test, tokenizer, block_size)\n",
        "dl_test = DataLoader(ds_test, batch_size=batch_size)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# you may load the model using the code:\n",
        "# model = AutoModelForCausalLM.from_pretrained(target_model_dir, dtype=\"auto\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72c1fef",
      "metadata": {
        "id": "e72c1fef"
      },
      "source": [
        "### MIA\n",
        "\n",
        "Implement your attack here! \\\n",
        "Hint: use shadow models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8875cce",
      "metadata": {
        "id": "e8875cce"
      },
      "outputs": [],
      "source": [
        "# implement your attack here\n",
        "@torch.no_grad()\n",
        "def your_attack(\n",
        "\n",
        "):\n",
        "    pass\n",
        "\n",
        "scores_test = your_attack(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe128e",
      "metadata": {
        "id": "59fe128e"
      },
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae9279c",
      "metadata": {
        "id": "0ae9279c"
      },
      "outputs": [],
      "source": [
        "# load the label here to compute the performance, you will only have full access to the label in train set to test your method\n",
        "if phase == \"train\":\n",
        "    label_path = data_dir / \"test_label.json\"\n",
        "    label_items = _read_json(label_path)\n",
        "\n",
        "    y_true = np.array(label_items)\n",
        "    scores = np.array(scores_test)\n",
        "    fpr, tpr, thr = roc_curve(y_true, scores)\n",
        "    auc_val = roc_auc_score(y_true, scores)\n",
        "    print(auc_val)\n",
        "\n",
        "    print(max(tpr[fpr < 0.01])) # TPR @ 0.01FPR\n",
        "    # WE ONLY CARE TPR @ 0.01FPR!!! SO INCREASE THIS AS MUCH AS POSSIBLE!!!\n",
        "elif phase == \"val\" or phase == \"final\":\n",
        "    pred_path = data_dir / \"prediction.csv\"\n",
        "    with open(pred_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for s in scores_test:\n",
        "            f.write(json.dumps(float(s), ensure_ascii=False) + \"\\n\")\n",
        "else:\n",
        "    print(\"Wrong phase.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28be0f7c",
      "metadata": {},
      "source": [
        "### Packaging the submission\n",
        "\n",
        "zip the prediction file and upload to the leaderboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f7cd4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(f\"project_submission.zip\", 'w') as zipf:\n",
        "    for phase in [\"val\", \"final\"]:\n",
        "        data_dir = f\"./data/{phase}/\"\n",
        "        data_dir = Path(data_dir)\n",
        "\n",
        "        file = data_dir / \"prediction.csv\"\n",
        "        if file.exists():\n",
        "            arcname = os.path.join(phase, file.name)\n",
        "            zipf.write(file, arcname=arcname)\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"`prediction.csv` not found in {data_dir}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52fe5f6e",
      "metadata": {},
      "source": [
        "### Visualization\n",
        "\n",
        "A few visualizations that may help you develop your method and write reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244336f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = 1e-12                   \n",
        "fpr_ = np.clip(fpr, 1e-5, 1) \n",
        "tpr_ = np.clip(tpr, 1e-5, 1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "ax.plot(fpr_, tpr_, lw=2, label=f'ROC (AUC = {auc_val:.4f})')\n",
        "ax.plot([1e-5, 1], [1e-5, 1], lw=2, ls='--', label='Chance')\n",
        "\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "ax.set_xlim(1e-5, 1.0)\n",
        "ax.set_ylim(1e-5, 1.0)\n",
        "\n",
        "ticks = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.get_xaxis().set_minor_formatter(plt.NullFormatter())\n",
        "ax.get_yaxis().set_minor_formatter(plt.NullFormatter())\n",
        "\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('MIA ROC (logâ€“log focus on small FPR/TPR)')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, which='both', alpha=0.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f14839",
      "metadata": {},
      "outputs": [],
      "source": [
        "# draw distribution\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# y_true = np.array(label_items)\n",
        "# scores = np.array(scores_test)\n",
        "\n",
        "scores_mem = scores[y_true == 1]\n",
        "scores_non = scores[y_true == 0]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(scores_mem, bins=50, color='salmon', kde=True, label='member')\n",
        "sns.histplot(scores_non, bins=50, color='skyblue', kde=True, label='non-member')\n",
        "\n",
        "threshold_value = np.percentile(scores_non, q=99)\n",
        "print(threshold_value)\n",
        "plt.axvline(\n",
        "    x=threshold_value,\n",
        "    color='purple',\n",
        "    linestyle='--',\n",
        "    linewidth=2,\n",
        "    label=f'0.01 FPR: {threshold_value:.2f}'\n",
        ")\n",
        "\n",
        "\n",
        "plt.title('Loss distribution', fontsize=16)\n",
        "plt.xlabel('Loss', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(fontsize=10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2e08d5",
      "metadata": {
        "id": "de2e08d5"
      },
      "outputs": [],
      "source": [
        "# draw ROC curve and attach the figure in the report\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_val:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance line')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title(f'MIA ROC Curve for Train Data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
